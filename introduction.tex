% !TEX root = 15cvpr.tex
\section{Introduction}

\begin{figure}[t]
<<<<<<< HEAD
	\begin{center}
   %\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   		\includegraphics[width=0.95\linewidth]{noisyparsing.pdf}
	\end{center}
   \caption{Example of caption.  It is set in Roman so that mathematics
   (always set in Roman: $B \sin A = A \sin B$) may be included without an
   ugly clash.}
\label{fig:noisyparsing}
=======
\begin{center}
    \includegraphics[width=1\linewidth]{noisyparsing.pdf}
\end{center}
    \caption{Given a training set of real-world images and its associated labels where label may be precise (green), incorrect (red) or missing (blue), we learn a model that segments and recognizes visual concept in new images. Best viewed in color.}
\label{fig:noisylabel}
>>>>>>> cf0ff95865e67670e9c4bf0288e4e1967828d7b4
\end{figure}

Semantic segmentation, an attractive but challenging task in computer vision community, is an efficient way to handle an explosive growth in the volume of image in real world. Aiming to assign each pixel to one of predefined semantic categories, machine learning methods are used to learn classifier from labeled training images. Most state-of-the-art approaches heavily relies on extensive guidance in training, using a sufficiently huge amount of annotated samples, while the truth is only a subset of large-scale image dataset can be manual labeled, due to its time-consuming and labor-intensive. Recent works have begun to address the semantic segmentation problem under the weakly supervised settings, where each training image is annotated by image-level labels specifying which classes are present but no pixel-level annotation is given \cite{verbeek2007region,vezhnevets2010towards,vezhnevets2011weakly,vezhnevets2012weakly,xu2014tell,zhang2013sparse,zhang2013probabilistic}. With the prevalence of photo sharing websites and collaborative image tagging system, such as Flickr, which host vast of digital images with user provided tags, such weakly supervised methods are more flexible in real-world applications since the image-level annotated images are much easier to obtain.

Inspired by these works, we focus on the problem of , which further relaxes the prerequisites for annotations(\eg labels must be precise and complete). We tackle semantic segmentation in real-world settings where only source of annotation are image-level labels encoding which categories are present in the image, and worse, the annotation can be noisy. It is worth noting that the annotations of collaboratively-tagged images may not be accurate (incorrect or incomplete) in practice, but such noisily tagged annotation has been ignored in recent work. It is not a realistic assumption in many real-world settings because collecting large-scale images with clean labels is still a labor-intensive task. Figure \ref{fig:noisyparsing} illustrates a set of representative real-world images and its associated tags. We can observe that only limited tags accurately describe the visual content of the image, while other tags are imprecise. Meanwhile, some important tags, which are highly associated with the image, are missing.

Aiming to overcome the challenge posed by noisy annotations, we present a weakly supervised method which achieves results competitive with fully supervised methods. {\textcolor{red}{TBD:approach}}

To illustrate both robustness and effectiveness of our method, {\textcolor{red}{we present experiment results on three challenging datasets which are representative of the difficulties of annotation noise present in real-world images.}} Our method outperforms previous state-of-the-art approaches on standard datasets, {\textcolor{red}{demonstrating that the image-level annotation are more efficiently utilized by our method}}. Moreover, our approach {\textcolor{red}{TBD:Noise Refine and Prediction}}

The main contributions of this paper are summarized as follows:
\begin{enumerate}
  \item We propose an weakly supervised semantic segmentation framework in noisily annotation condition.
  \item We design a novel CRF model that jointly models various contextual relations in a single framework. It can be investigated from different perspectives: both appearance model and latent semantic categories distribution, inter-class label co-relation, image-level and pixel-level label consistency.
  \item We propose a efficient method to model that jointly captures label statistics and discriminative regions of each category.
\end{enumerate}

\if
In the past few years, many different methods \cite{csurka2011efficient,gonfaus2010harmony,ladicky2009associative,nowozin2010parameter,shotton2008semantic,shotton2006textonboost,singh2013nonparametric,verbeek2007scene,yang2007multiple,yao2012describing} have been proposed for this task. Notwithstanding significant improvements they have achieved, most of them rely on full supervision: each pixel of the image for training is manually labeled by humans. The performance of these fully supervised methods heavily relies on a sufficiently huge amount of annotated samples, while the truth is only a subset of large-scale image dataset can be manual labeled, due to its time-consuming and labor-intensive. Therefore, these methods are inherently limited so that such system cannot be widely applied in practice.

Recently, a few works have been proposed to address the semantic segmentation problem under the weakly supervised settings, where each training image is annotated by image-level labels specifying which classes are present but no pixel-level annotation is given \cite{verbeek2007region,vezhnevets2010towards,vezhnevets2011weakly,vezhnevets2012weakly,xu2014tell,zhang2013sparse,zhang2013probabilistic}. Different from the traditional supervised semantic segmentation, such weakly supervised method is more flexible in real-world applications for the image-level annotated images are much easier to obtain. With the prevalence of photo sharing websites and collaborative image tagging system, such as Flickr, which host vast of digital images with user provided tags, this weakly supervised setting for image parsing become more and more feasible.

 Fortunately, owing to the collaborative image tagging system, \eg Flickr, we can easily obtain a large mount of manually labeled images provided by Internet users, though these image-level labels might be noisy (incorrect or incomplete). Therefore, the main challenge lies in how to utilize the noisily labeled images for semantic segmentation (see Figure \ref{fig:noisyparsing} for an illustration).


 Moreover, most existing semantic segmentation methods, either fully or weakly supervised, depend on a single choice of image partitioning (quantization). The precise quantization of an image is of significance, and it is less likely to obtain a common optimal quantization (partitioning) level suitable for every object. To overcome this problem, \cite{hoiem2005geometric,kohli2009robust,ladicky2009associative,nowozin2010parameter,russell2006using} used multiple segmentations of the image and achieved good performances by heuristic strategies or enforcing label consistency with higher order potential.

It is worth noting that the annotations of collaboratively-tagged images may not be accurate (incorrect or incomplete) in practice, but such noisily tagged annotation has been ignored in recent work. Moreover, there are some extra prerequisites (\eg labels must be precise and complete) for the initial image-level labels in existed weakly supervised semantic segmentation systems, while collecting such training images that satisfy all these constraints is still a labor-intensive task. Figure \ref{fig:noisyparsing} illustrates a set of representative real-world images and its associated tags. We can observe that only limited tags accurately describe the visual content of the image, while other tags are imprecise. Meanwhile, some important tags, which are highly associated with the image, are missing. Therefore, the main challenge lies in how to utilize the noisily labeled images for semantic segmentation.
\fi
